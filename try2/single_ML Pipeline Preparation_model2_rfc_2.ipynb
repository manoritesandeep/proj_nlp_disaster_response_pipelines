{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\manor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(['stopwords','wordnet','punkt','averaged_perceptron_tagger'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# KNeighbor Classifier - K-Nearest Neighbors (KNN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table(\"Message\", engine)\n",
    "df = df.sample(frac=0.5)\n",
    "X = df['message']\n",
    "y = df.drop(['id', 'message', 'original', 'genre'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df type: <class 'pandas.core.frame.DataFrame'>\n",
      "Len of df: 13108\n",
      "Shape of X: (13108,),\n",
      "Shape of Y: (13108, 37)\n",
      "['index', 'id', 'message', 'original', 'genre', 'related', 'request', 'offer', 'aid_related', 'medical_help', 'medical_products', 'search_and_rescue', 'security', 'military', 'child_alone', 'water', 'food', 'shelter', 'clothing', 'money', 'missing_people', 'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport', 'buildings', 'electricity', 'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure', 'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold', 'other_weather', 'direct_report']\n"
     ]
    }
   ],
   "source": [
    "print(f\"df type: {type(df)}\\nLen of df: {len(df)}\")\n",
    "print(f\"Shape of X: {X.shape},\\nShape of Y: {y.shape}\")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(df.isnull())\n",
    "\n",
    "# # Check nulls\n",
    "# 100 * (df.isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(text):\n",
    "#     # Tokenize text into words\n",
    "#     words = list(chain.from_iterable([word_tokenize(t) for t in text]))\n",
    "    \n",
    "#     # Remove stopwords\n",
    "#     words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "#     # Tag words with POS\n",
    "#     tagged_words = pos_tag(words)\n",
    "    \n",
    "#     # Initiate lemmatizer\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "#     clean_tokens = []\n",
    "#     # Iterate through each tagged word\n",
    "#     for word, tag in tagged_words:\n",
    "#         # Lemmatize based on POS tag\n",
    "#         # if tag.startswith('N'):\n",
    "#         #     clean_tok = lemmatizer.lemmatize(word, pos='n').lower().strip()\n",
    "#         # elif tag.startswith('V'):\n",
    "#         #     clean_tok = lemmatizer.lemmatize(word, pos='v').lower().strip()\n",
    "#         # elif tag.startswith('J'):\n",
    "#         #     clean_tok = lemmatizer.lemmatize(word, pos='a').lower().strip()\n",
    "#         # else:\n",
    "#         #     clean_tok = lemmatizer.lemmatize(word).lower().strip()\n",
    "#         clean_tok = lemmatizer.lemmatize(word).lower().strip()\n",
    "#         clean_tokens.append(clean_tok)\n",
    "    \n",
    "#     return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize1(text):\n",
    "#     words = list(chain.from_iterable([word_tokenize(t) for t in text]))\n",
    "#     stop_words = set(stopwords.words(\"english\"))\n",
    "#     tagged_words = pos_tag(words)\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     clean_tokens = [lemmatizer.lemmatize(word).lower().strip() for word, tag in tagged_words if word not in stop_words]\n",
    "#     return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize2(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tagged_words = pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(word).lower().strip() for word, tag in tagged_words if word.lower().strip() not in stop_words]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(tokenizer=tokenize2)),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9175,) (9175, 37) (3933,) (3933, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manor\\Downloads\\05 Project_Disaster Resoponse Pipelines\\proj_uda_nlpdis_venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.3)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     target_names \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m---> 10\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred, target_names\u001b[39m=\u001b[39;49mtarget_names))\n",
      "File \u001b[1;32mc:\\Users\\manor\\Downloads\\05 Project_Disaster Resoponse Pipelines\\proj_uda_nlpdis_venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\manor\\Downloads\\05 Project_Disaster Resoponse Pipelines\\proj_uda_nlpdis_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2405\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   2406\u001b[0m     {\n\u001b[0;32m   2407\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2431\u001b[0m ):\n\u001b[0;32m   2432\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \n\u001b[0;32m   2434\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2536\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2537\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2541\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2542\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\manor\\Downloads\\05 Project_Disaster Resoponse Pipelines\\proj_uda_nlpdis_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    107\u001b[0m     y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test is a DataFrame or NumPy array with the same shape as y_pred\n",
    "if isinstance(y_test, np.ndarray):\n",
    "    target_names = np.unique(y_test).astype(str)\n",
    "else:\n",
    "    target_names = y_test.columns.tolist()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# X_train = pd.Series(X_train)\n",
    "# y = pd.Series(y)\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: index\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i, column \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(y\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCategory: \u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mprint\u001b[39m(classification_report(y_test[column], y_pred[:, i]))\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Iterate through each output category and calculate the F1 score, precision, and recall\n",
    "for i, column in enumerate(y.columns):\n",
    "    print(f\"Category: {column}\\n\")\n",
    "    print(classification_report(y_test[column], y_pred[:, i]))\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    pipeline = Pipeline([\n",
    "        # ('vect',CountVectorizer(tokenizer=tokenize1)),\n",
    "        # ('tfidf', TfidfTransformer()),\n",
    "        ('vect', TfidfVectorizer(tokenizer=tokenize)),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    # specify parameters for grid search\n",
    "    parameters = {\n",
    "        \"vect__ngram_range\":[(1,1),(1,2)],\n",
    "        \"clf__n_estimators\": [10,50,100],\n",
    "        \"clf__min_samples_split\":[2, 3, 4],\n",
    "        \"clf__criterion\":[\"gini\", \"entropy\"]\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each output category and calculate the F1 score, precision, and recall\n",
    "for i, column in enumerate(y.columns):\n",
    "    print(f\"Category: {column}\\n\")\n",
    "    print(classification_report(y_test[column], y_pred[:, i]))\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to pickle file\n",
    "\n",
    "with open('rfc_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model():\n",
    "#     models = []\n",
    "\n",
    "#     pipeline_rf = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "#     ])\n",
    "    \n",
    "#     parameters_rf = {\n",
    "#         'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#         'clf__estimator__n_estimators': [10, 50, 100],\n",
    "#         'clf__estimator__min_samples_split': [2, 3, 4],\n",
    "#         # 'clf__estimator__criterion': ['gini', 'entropy']\n",
    "#     }\n",
    "    \n",
    "#     cv_rf = GridSearchCV(pipeline_rf, param_grid=parameters_rf)\n",
    "#     models.append(('RandomForestClassifier', cv_rf))\n",
    "\n",
    "    # pipeline_lr = Pipeline([\n",
    "    #     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    #     ('clf', MultiOutputClassifier(LogisticRegression()))\n",
    "    # ])    \n",
    "    \n",
    "    # parameters_lr = {\n",
    "    #     \"vect__ngram_range\": [(1, 1), (1, 2)],\n",
    "    #     \"clf__estimator__C\": [0.1, 1, 10],\n",
    "    #     # \"clf__estimator__solver\": [\"lbfgs\", \"liblinear\"]\n",
    "    # }\n",
    "    \n",
    "    # cv_lr = GridSearchCV(pipeline_lr, param_grid=parameters_lr)\n",
    "    # models.append(('LogisticRegression', cv_lr))\n",
    "    \n",
    "    # pipeline_svc = Pipeline([\n",
    "    #     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    #     ('clf', MultiOutputClassifier(SVC()))\n",
    "    # ])\n",
    "    \n",
    "    # parameters_svc = {\n",
    "    #     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    #     'clf__estimator__C': [1, 10],\n",
    "    #     'clf__estimator__kernel': ['linear', 'rbf']\n",
    "    # }\n",
    "    \n",
    "    # cv_svc = GridSearchCV(pipeline_svc, param_grid=parameters_svc)\n",
    "    # models.append(('SVC', cv_svc))\n",
    "    \n",
    "    # pipeline_gb = Pipeline([\n",
    "    #     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    #     ('clf', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    # ])\n",
    "    \n",
    "    # parameters_gb = {\n",
    "    #     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    #     'clf__estimator__n_estimators': [50, 100],\n",
    "    #     'clf__estimator__learning_rate': [0.1, 0.5]\n",
    "    # }\n",
    "    \n",
    "    # cv_gb = GridSearchCV(pipeline_gb, param_grid=parameters_gb)\n",
    "    # models.append(('GradientBoosting', cv_gb))\n",
    "    \n",
    "    # pipeline_kneigh = Pipeline([\n",
    "    #     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    #     ('clf', MultiOutputClassifier(KNeighborsClassifier()))\n",
    "    # ])\n",
    "    \n",
    "    # parameters_kneigh = {\n",
    "    #     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    #     'clf__estimator__n_neighbors': [3, 5, 7],\n",
    "    #     # 'clf__estimator__weights': ['uniform', 'distance']\n",
    "    # }\n",
    "    \n",
    "    # cv_kneigh = GridSearchCV(pipeline_kneigh, param_grid=parameters_kneigh)\n",
    "    # models.append(('KNeighborsClassifier', cv_kneigh))\n",
    "    \n",
    "    # pipeline_naive = Pipeline([\n",
    "    #     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    #     ('tfidf', TfidfTransformer()),\n",
    "    #     ('clf', MultiOutputClassifier(MultinomialNB()))\n",
    "    # ])\n",
    "    \n",
    "    # parameters_naive = {\n",
    "    #     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    #     'clf__estimator__alpha': [0.5, 1.0]\n",
    "    # }\n",
    "    \n",
    "    # cv_naive = GridSearchCV(pipeline_naive, param_grid=parameters_naive)\n",
    "    # models.append(('MultinomialNB', cv_naive))\n",
    "\n",
    "    # return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = build_model()\n",
    "# for model_name, model in models:\n",
    "#     print(f\"Training {model_name}...\")\n",
    "#     model.fit(X_train, y_train)\n",
    "#     print(f\"Evaluating {model_name}...\")\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(f\"Classification Report for {model_name}:\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = build_model()\n",
    "# # Train and evaluate models\n",
    "# best_model = None\n",
    "# best_model_name = None\n",
    "# best_model_score = 0\n",
    "\n",
    "# for model_name, model in models:\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     score = classification_report(y_test, y_pred)\n",
    "    \n",
    "#     if score > best_model_score:\n",
    "#         best_model_score = score\n",
    "#         best_model = model\n",
    "#         best_model_name = model_name\n",
    "\n",
    "# # Save the best model as a pickle file\n",
    "# with open('best_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(best_model, f)\n",
    "\n",
    "# print(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
